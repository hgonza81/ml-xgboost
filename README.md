# ML API Platform

A complete machine learning platform with FastAPI prediction service, MLflow experiment tracking, and containerized deployment.

## Project Structure

```
ml-api-platform/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ api/                      # FastAPI prediction service
â”‚   â”œâ”€â”€ mlflow_components/        # MLflow tracking and registry
â”‚   â”œâ”€â”€ training/                 # Model training pipeline
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ config/                       # Configuration management
â”‚   â”œâ”€â”€ settings.py              # Pydantic settings with validation
â”‚   â”œâ”€â”€ development.env          # Development environment config
â”‚   â”œâ”€â”€ production.env           # Production environment config
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ deployment/                   # Deployment configurations
â”‚   â”œâ”€â”€ lambda_handler.py        # AWS Lambda handler
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ tests/                        # Test suite
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ data/                         # Data storage (created at runtime)
â”œâ”€â”€ Dockerfile.api               # FastAPI service container
â”œâ”€â”€ Dockerfile.mlflow            # MLflow server container
â”œâ”€â”€ Dockerfile.lambda            # AWS Lambda container
â”œâ”€â”€ docker-compose.yml           # Development orchestration
â”œâ”€â”€ pyproject.toml              # Python project configuration
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ Makefile                    # Development commands
â”œâ”€â”€ .env.example               # Environment variables template
â”œâ”€â”€ .gitignore                 # Git ignore rules
â””â”€â”€ README.md                  # This file
```

## Quick Start

### Development Environment

1. **Clone and setup**:
   ```bash
   git clone <repository-url>
   cd ml-api-platform
   cp .env.example .env
   # Edit .env with your configuration
   ```

2. **Start development environment**:
   ```bash
   make dev
   # or
   docker-compose up -d
   ```

3. **Access services**:
   - API: http://localhost:8000
   - API Documentation: http://localhost:8000/docs
   - MLflow UI: http://localhost:5000

### Local Development (without Docker)

1. **Install dependencies**:
   ```bash
   pip install -e ".[dev]"
   ```

2. **Set environment**:
   ```bash
   export ENVIRONMENT=development
   source config/development.env
   ```

## Configuration

The platform uses environment-specific configuration with validation:

- **Development**: Uses SQLite for MLflow backend, local file storage
- **Production**: Uses S3 for artifacts, AWS services for secrets and monitoring

Configuration is managed through:
- `config/settings.py`: Pydantic models with validation
- `config/development.env`: Development environment variables
- `config/production.env`: Production environment template
- `.env`: Local overrides (not committed)

## Available Commands

```bash
make help           # Show all available commands
make install-dev    # Install development dependencies
make test           # Run test suite
make lint           # Run code quality checks
make format         # Format code
make build          # Build Docker images
make up             # Start development environment
make down           # Stop development environment
make logs           # Show service logs
make train          # Run training pipeline
```

## Environment Variables

Key environment variables (see `.env.example` for complete list):

- `ENVIRONMENT`: `development` or `production`
- `API_KEY`: Authentication key for API access
- `MLFLOW_TRACKING_URI`: MLflow server URL
- `MODEL_NAME`: Model name in MLflow registry
- `MODEL_STAGE`: Model stage to load (`staging`, `production`)

## Next Steps

This is the foundational project structure. The next tasks will implement:

1. FastAPI prediction service with authentication
2. MLflow integration for model loading
3. Model training pipeline with XGBoost
4. CI/CD pipeline with GitHub Actions
5. Production deployment to AWS Lambda

## Development Workflow

1. Make changes to source code
2. Run tests: `make test`
3. Check code quality: `make lint`
4. Format code: `make format`
5. Build and test locally: `make up`
6. Commit changes and push

## Architecture

The platform follows a microservices architecture:

- **API Service**: FastAPI application serving predictions
- **MLflow Service**: Experiment tracking and model registry
- **Training Service**: Model training and hyperparameter optimization
- **Deployment**: Container-based deployment to AWS Lambda

All services are containerized and orchestrated with Docker Compose for development, with production deployment to AWS Lambda using container images.

## Technology Stack

### ğŸ Base Language
- **Python 3.11+** â€“ Main programming language of the project

---

### ğŸš€ Web Framework & API
- **FastAPI (>=0.104.0)** â€“ Modern, high-performance web framework for APIs  
- **Uvicorn (>=0.24.0)** â€“ ASGI server for running FastAPI  
- **Pydantic (>=2.5.0)** â€“ Data validation and serialization  
- **python-multipart (>=0.0.6)** â€“ Multipart form data handling  

---

### ğŸ¤– Machine Learning & MLOps
- **MLflow (>=2.8.0)** â€“ MLOps platform for experiment tracking and model registry  
- **XGBoost (>=2.0.0)** â€“ Core machine learning algorithm  
- **scikit-learn (>=1.3.0)** â€“ Complementary ML library  
- **Pandas (>=2.1.0)** â€“ Data manipulation  
- **NumPy (>=1.24.0)** â€“ Numerical computing  
- **SciPy (>=1.11.0)** â€“ Scientific algorithms  
- **Joblib (>=1.3.0)** â€“ Model serialization  

---

### â˜ï¸ Cloud Services (AWS)
- **Boto3 (>=1.34.0)** â€“ AWS SDK for Python  
- **Botocore (>=1.34.0)** â€“ Core AWS SDK components  

---

### ğŸŒ HTTP & Networking
- **HTTPx (>=0.25.0)** â€“ Asynchronous HTTP client  
- **Requests (>=2.31.0)** â€“ Traditional synchronous HTTP client  

---

### ğŸ“Š Logging & Monitoring
- **Structlog (>=23.2.0)** â€“ Structured logging  
- **python-json-logger (>=2.0.7)** â€“ JSON logging formatter  

---

### âš™ï¸ Configuration
- **pydantic-settings (>=2.1.0)** â€“ Configuration management  
- **python-dotenv (>=1.0.0)** â€“ Environment variable management  

---

### ğŸ” Hyperparameter Optimization
- **Optuna (>=3.4.0)** â€“ Hyperparameter optimization framework  
- **optuna-integration[mlflow] (>=3.4.0)** â€“ MLflow integration for Optuna  

---

### ğŸ³ Containerization & Orchestration
- **Docker** â€“ Containerization for services  
- **Docker Compose** â€“ Local orchestration  
- **AWS Lambda** â€“ Serverless deployment (via `Dockerfile.lambda`)  

---

### ğŸ§ª Testing & Code Quality (Dev Dependencies)
- **pytest (>=7.4.0)** â€“ Testing framework  
- **pytest-asyncio (>=0.21.0)** â€“ Async testing support  
- **pytest-cov (>=4.1.0)** â€“ Code coverage reporting  
- **black (>=23.11.0)** â€“ Code formatter  
- **isort (>=5.12.0)** â€“ Import sorter  
- **flake8 (>=6.1.0)** â€“ Linter  
- **mypy (>=1.7.0)** â€“ Static type checker  
- **pre-commit (>=3.6.0)** â€“ Git hooks automation  

---

### ğŸ“ˆ Production Monitoring (Optional)
- **prometheus-client (>=0.19.0)** â€“ Prometheus metrics exporter  
- **sentry-sdk[fastapi] (>=1.38.0)** â€“ Error tracking and tracing  

---

### ğŸ—„ï¸ Databases (Production)
- **psycopg2-binary (>=2.9.9)** â€“ PostgreSQL adapter  
- **pymysql (>=1.1.0)** â€“ MySQL adapter  
- **SQLite** â€“ Default lightweight database for MLflow  

---

### ğŸ”§ Development Tools
- **jupyter (>=1.0.0)** â€“ Interactive notebooks for analysis  
- **ipython (>=8.17.0)** â€“ Enhanced interactive Python shell  
- **Make** â€“ Task automation (Makefile)  

---

### ğŸ—ï¸ System Architecture
- **Microservices** â€“ Separate API, MLflow, and Training services  
- **RESTful API** â€“ Standard REST endpoints  
- **API Key Authentication** â€“ Security mechanism  
- **CORS** â€“ Cross-Origin Resource Sharing policy  
- **Health Checks** â€“ Service health monitoring  
- **Multi-stage Docker builds** â€“ Optimized container images  

---

### ğŸ“ Configuration Structure
- **Environment-based config** â€“ Development vs. Production  
- **Pydantic Settings** â€“ Validated configuration system  
- **Docker environment files** â€“ Environment-specific variables  

---

### ğŸ”„ Workflow
- **MLflow Model Registry** â€“ Centralized model versioning  
- **Hyperparameter Optimization** â€“ Tuning with Optuna  
- **Model Promotion Pipeline** â€“ Controlled model rollout  
- **Experiment Tracking** â€“ Complete experiment traceability  